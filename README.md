# NVIDIA Voice Agent (C#)

A real-time voice agent built with ASP.NET Core 8 that performs Speech-to-Text (ASR), LLM processing, and Text-to-Speech (TTS) using NVIDIA NIM models via ONNX Runtime.

**Ported from:** [nvidia-transcribe/scenario5](https://github.com/elbruno/nvidia-transcribe/tree/main/scenario5)

## Features

- ğŸ¤ **Real-time Speech Recognition** - Parakeet-TDT-0.6B-V2 ASR model
- ğŸ¤– **LLM Integration** - Phi-3-mini-4k for conversational responses
- ğŸ”Š **Text-to-Speech** - FastPitch + HiFiGAN for natural voice synthesis
- ğŸŒ **WebSocket API** - Real-time bi-directional audio streaming
- ğŸ“± **Browser UI** - Ready-to-use web interface

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  ASP.NET Core 8 Server               â”‚
â”‚  (UI)       â”‚   /ws/voice        â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”        â”‚
                                   â”‚  â”‚ ASR â”‚â”€â”€â–ºâ”‚ LLM â”‚â”€â”€â–ºâ”‚ TTS â”‚        â”‚
                                   â”‚  â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜        â”‚
                                   â”‚  ONNX Runtime (GPU/CPU)              â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

- .NET 8.0 SDK
- (Optional) NVIDIA GPU with CUDA 11.8+ for GPU acceleration

### Run

```bash
cd src/NvidiaVoiceAgent
dotnet run
```

Open http://localhost:5000 in your browser.

### Run Tests

```bash
dotnet test
```

## Configuration

Edit `appsettings.json`:

```json
{
  "ModelConfig": {
    "AsrModelPath": "models/parakeet-tdt-0.6b-v2.onnx",
    "TtsModelPath": "models/fastpitch.onnx",
    "VocoderModelPath": "models/hifigan.onnx",
    "LlmModelPath": "models/phi-3-mini-4k-instruct.onnx"
  }
}
```

## API Endpoints

| Endpoint | Protocol | Description |
|----------|----------|-------------|
| `/ws/voice` | WebSocket | Voice processing pipeline |
| `/ws/logs` | WebSocket | Real-time log streaming |
| `/health` | HTTP GET | Health check |

## WebSocket Protocol

### Voice Endpoint (`/ws/voice`)

**Send:** Binary WAV audio (16kHz, mono, 16-bit PCM)

**Receive:**
```json
{ "type": "transcription", "text": "Hello world" }
{ "type": "response", "text": "Hi there!" }
{ "type": "audio", "data": "<base64 WAV>" }
```

## Project Structure

```
â”œâ”€â”€ src/NvidiaVoiceAgent/
â”‚   â”œâ”€â”€ Hubs/                  # WebSocket handlers
â”‚   â”‚   â”œâ”€â”€ VoiceWebSocketHandler.cs
â”‚   â”‚   â””â”€â”€ LogsWebSocketHandler.cs
â”‚   â”œâ”€â”€ Services/              # Core services
â”‚   â”‚   â”œâ”€â”€ AsrService.cs      # Speech recognition
â”‚   â”‚   â”œâ”€â”€ TtsService.cs      # Text-to-speech
â”‚   â”‚   â”œâ”€â”€ LlmService.cs      # Language model
â”‚   â”‚   â””â”€â”€ AudioProcessor.cs  # Audio utilities
â”‚   â”œâ”€â”€ Models/                # DTOs
â”‚   â””â”€â”€ wwwroot/               # Browser UI
â””â”€â”€ tests/NvidiaVoiceAgent.Tests/
```

## Model Requirements

| Model | Size | VRAM |
|-------|------|------|
| Parakeet-TDT-0.6B-V2 | ~1.2GB | 2-4GB |
| FastPitch + HiFiGAN | ~250MB | ~1GB |
| Phi-3-mini-4k (int4) | ~2GB | ~4GB |

**Total recommended:** 6-8GB VRAM for full pipeline

## Development

The project runs in **mock mode** when model files are not present, allowing development without downloading large models.

### Adding Models

1. Download ONNX models from NVIDIA NIM or Hugging Face
2. Place in `models/` directory (or configure paths in appsettings.json)
3. Restart the server

## License

MIT

## Credits

- Original Python implementation: [nvidia-transcribe](https://github.com/elbruno/nvidia-transcribe)
- NVIDIA NIM models
- ONNX Runtime
